{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1、引入库函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "# 引入常规库函数\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 引入统计函数库\n",
    "# 网上此种引入方法比较普遍\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.tsa.stattools as ts\n",
    "\n",
    "# 引入Kalman函数库\n",
    "from pykalman import KalmanFilter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2、定义相应的自定义函数，提取对应的股票对"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 股票名：get_pairs\n",
    "# 输入参数：\n",
    "# 1、current_date：提取数据截止的时间点\n",
    "# 2、ncount：提取的样本数\n",
    "# 返回值：\n",
    "# pandas数组，包含交易的股票配对信息、beta、alpha、hurst、half-life、category等信息\n",
    "# 功能：\n",
    "# 利用聚宽的行业分类、价格信息，按照行业分类提取相应的股票对，同时比较节约时间\n",
    "\n",
    "def get_pairs(current_date,ncount):\n",
    "    # 最终的返回值数据\n",
    "    ret = pd.DataFrame()\n",
    "    \n",
    "    # 按照聚宽的行业分类，进行相应的数据提取工作\n",
    "    # 参考聚宽申万二级行业列表\n",
    "    industry_list = [\"HY401\",\"HY402\",\"HY403\",\"HY404\",\"HY405\",\"HY406\",\"HY407\",\"HY408\",\"HY409\",\"HY410\", \\\n",
    "                 \"HY411\",\"HY412\",\"HY413\",\"HY414\",\"HY415\",\"HY416\",\"HY417\",\"HY418\",\"HY419\",\"HY420\", \\\n",
    "                 \"HY421\",\"HY422\",\"HY423\",\"HY424\",\"HY425\",\"HY426\",\"HY427\",\"HY428\",\"HY429\",\"HY432\", \\\n",
    "                 \"HY433\",\"HY434\",\"HY435\",\"HY436\",\"HY437\",\"HY438\",\"HY439\",\"HY440\",\"HY441\",\"HY442\", \\\n",
    "                 \"HY443\",\"HY444\",\"HY445\",\"HY446\",\"HY447\",\"HY448\",\"HY449\",\"HY450\",\"HY451\",\"HY452\", \\\n",
    "                 \"HY453\",\"HY454\",\"HY455\",\"HY457\",\"HY458\",\"HY459\",\"HY460\",\"HY461\",\"HY462\",\"HY463\", \\\n",
    "                 \"HY464\",\"HY465\",\"HY466\",\"HY467\",\"HY468\",\"HY469\",\"HY470\",\"HY471\",\"HY472\",\"HY473\", \\\n",
    "                 \"HY474\",\"HY476\",\"HY477\",\"HY478\",\"HY479\",\"HY480\",\"HY481\",\"HY483\",\"HY484\",\"HY485\", \\\n",
    "                 \"HY486\",\"HY487\",\"HY488\",\"HY489\",\"HY491\",\"HY492\",\"HY493\",\"HY494\",\"HY496\",\"HY497\", \\\n",
    "                 \"HY500\",\"HY501\",\"HY504\",\"HY505\",\"HY506\",\"HY509\",\"HY510\",\"HY511\",\"HY512\",\"HY513\", \\\n",
    "                 \"HY514\",\"HY515\",\"HY516\",\"HY517\",\"HY518\",\"HY519\",\"HY520\",\"HY521\",\"HY523\",\"HY524\", \\\n",
    "                 \"HY525\",\"HY526\",\"HY527\",\"HY528\",\"HY529\",\"HY530\",\"HY531\",\"HY570\",\"HY571\",\"HY572\", \\\n",
    "                 \"HY573\",\"HY574\",\"HY576\",\"HY578\",\"HY579\",\"HY587\",\"HY588\",\"HY591\",\"HY593\",\"HY595\", \\\n",
    "                 \"HY596\",\"HY597\",\"HY598\",\"HY601\"]\n",
    "    \n",
    "    # 证监会行业列表\n",
    "    industry_list = [\"A01\",\"A02\",\"A03\",\"A04\",\"A05\",\"B06\",\"B07\",\"B08\",\"B09\",\"B10\",\"B11\", \\\n",
    "                 \"B12\",\"C13\",\"C14\",\"C15\",\"C16\",\"C17\",\"C18\",\"C19\",\"C20\",\"C21\",\"C22\", \\\n",
    "                 \"C23\",\"C24\",\"C25\",\"C26\",\"C27\",\"C28\",\"C29\",\"C30\",\"C31\",\"C32\",\"C33\", \\\n",
    "                 \"C34\",\"C35\",\"C36\",\"C37\",\"C38\",\"C39\",\"C40\",\"C41\",\"C42\",\"C43\",\"D44\", \\\n",
    "                 \"D45\",\"D46\",\"E47\",\"E48\",\"E49\",\"E50\",\"F51\",\"F52\",\"G53\",\"G54\",\"G55\", \\\n",
    "                 \"G56\",\"G57\",\"G58\",\"G59\",\"G60\",\"H61\",\"H62\",\"I63\",\"I64\",\"I65\",\"J66\", \\\n",
    "                 \"J67\",\"J68\",\"J69\",\"K70\",\"L71\",\"L72\",\"M73\",\"M74\",\"M75\",\"N76\",\"N77\", \\\n",
    "                 \"N78\",\"O79\",\"O80\",\"O81\",\"P82\",\"Q83\",\"Q84\",\"R85\",\"R86\",\"R87\",\"R88\",\"R89\",\"S90\"]\n",
    "    \n",
    "    # 开始进行行业循环，提取相应的\n",
    "    for industry_list_i in industry_list:\n",
    "\n",
    "        print \"开始计算：%s\"%str(industry_list_i)\n",
    "        \n",
    "        # 清空存储数据\n",
    "        # 用于整理数据，中间暂存每个配对对应的pearson、beta等相关信息\n",
    "        data_pd = pd.DataFrame()\n",
    "        \n",
    "        # 清空存储配对数据\n",
    "        pairs = []\n",
    "        \n",
    "        # 清空数据\n",
    "        stock_list = []\n",
    "        \n",
    "        # 获取行业列表\n",
    "        stock_list = get_industry_stocks(industry_list_i, date= current_date)\n",
    "        \n",
    "        try:\n",
    "            # 获取核心的分析数据\n",
    "            # cor_data_collect是下一个核心函数\n",
    "            # cor_data的数据结构：\n",
    "            # 字典结构，键为（pair1，pair2）元组，值为数组[pearson_factor,adf_factor,beta,alpha,hurst,half-life]\n",
    "            cor_data = cor_data_collect(stock_list,day_count = ncount,end_date = current_date)\n",
    "        \n",
    "        except:\n",
    "            print \"提取行业数据出错\"\n",
    "        \n",
    "        \n",
    "        # 剔除一部分数据不相关的数据\n",
    "        # 目标为：adf检测为假的数据\n",
    "        for k,v in cor_data.items():\n",
    "            \n",
    "            # 如果长度小于3，说明没有进行Adf等后续的检测，所以没有必要进行进一步的检查\n",
    "            if len(v) > 3:\n",
    "                # 增加了行业industry数据\n",
    "                pairs.append([k,v,industry_list_i])\n",
    "    \n",
    "        # 对配对数据进行整理，合并所有数据\n",
    "        data_pd = pd.concat([pd.DataFrame([p[0] for p in pairs],columns = ['p1','p2']), \\\n",
    "                            pd.DataFrame([p[1] for p in pairs],columns = ['pearson','adf','beta','alpha','hurst','half-life']),\\\n",
    "                            pd.DataFrame([p[2] for p in pairs],columns = ['category'])], \\\n",
    "                            axis = 1)\n",
    "\n",
    "        # 合并数据\n",
    "        # 如果需要，在合并数据的时候可以进行数据筛选\n",
    "        ret = pd.concat([ret,data_pd],axis = 0)\n",
    "    return ret\n",
    "\n",
    "\n",
    "\n",
    "# 函数名：cor_data_collect\n",
    "# 输入参数：\n",
    "# 1、stock_list：比对的股票列表\n",
    "# 2、day_count：选取的每支股票的样本数\n",
    "# 3、end_date：终止时间\n",
    "# 输出参数：\n",
    "# ret：\n",
    "# 字典结构，键为（pair1，pair2）元组，值为数组[pearson_factor,adf_factor,beta,alpha,hurst,half-life]\n",
    "# 功能：\n",
    "# 从所给出的stock_list中，两两配对，计算相关系数\n",
    "def cor_data_collect(stock_list,day_count,end_date):\n",
    "    # 获取股票列表的价格数据\n",
    "    pdata = get_price(stock_list, count = day_count, end_date=end_date, frequency='daily', fields='close',fq = \"pre\")['close']\n",
    "\n",
    "    # Nan数据填充为0 \n",
    "    pdata = pdata.dropna(0)\n",
    "\n",
    "    # 找到列数\n",
    "    n = pdata.shape[1]\n",
    "\n",
    "    # 找到列名\n",
    "    keys = pdata.keys()\n",
    "\n",
    "    # 最终返回的存储结果\n",
    "    ret = {}\n",
    "    \n",
    "    # 输出处理进度\n",
    "    print \"行业内合计股票数为：%d\"%int(n)\n",
    "    \n",
    "    # 逐项配对，进行匹配验证\n",
    "    # 按照获取的股票数量\n",
    "    for i in range(n):\n",
    "        \n",
    "        # 对数据进行循环比对\n",
    "        for j in range(i+1, n):\n",
    "            \n",
    "            # 赋初值，数据为价格\n",
    "            S1 = pdata[keys[i]]\n",
    "            S2 = pdata[keys[j]]\n",
    "\n",
    "            \n",
    "            ################    开始进行处理，共5步          ########################\n",
    "            \n",
    "            # 1、赋初值,以二者股票的元组为键值\n",
    "            ret[(keys[i],keys[j])] = []\n",
    "            \n",
    "            # 2、计算Pearson相关系数\n",
    "            # calcPearson为自定义函数，见后注释\n",
    "            pearson_cor = calcPearson(S1,S2)\n",
    "            ret[(keys[i],keys[j])].append(pearson_cor)\n",
    "            \n",
    "            try:\n",
    "                # 如果pearson相关系数高，则进行下一步，否则暂缓\n",
    "                # 主要目的是节约时间\n",
    "                if abs(pearson_cor) > 0.6:\n",
    "                    \n",
    "                    # 3、计算相关CADF数据\n",
    "                    # 初值均赋值为最小项\n",
    "                    adf_factor = False\n",
    "                    beta = 0\n",
    "                    alpha = 0 \n",
    "\n",
    "                    # Cadf_test为自定义函数，见后注释\n",
    "                    adf_factor,beta,alpha = Cadf_test(keys[i],keys[j],day_count,end_date)\n",
    "\n",
    "                    # 节约运算时间，如果的确是均值回归，再进行计算\n",
    "                    if adf_factor:\n",
    "                        \n",
    "                        # 数组中追加述职\n",
    "                        ret[(keys[i],keys[j])].append(adf_factor)\n",
    "                        ret[(keys[i],keys[j])].append(beta)\n",
    "                        ret[(keys[i],keys[j])].append(alpha)\n",
    "\n",
    "                        # 4、计算hurst\n",
    "                        # 需要先计算两者的残差\n",
    "                        residual = pd.Series(S1 - beta * S2 - alpha)\n",
    "\n",
    "                        #  数据为负会出错，所以加100\n",
    "                        # hurst为自定义函数，见后注释\n",
    "                        ret[(keys[i],keys[j])].append(hurst(residual+100))\n",
    "\n",
    "                        # 5、计算half-life\n",
    "                        # half_life为自定义函数，见后注释\n",
    "                        ret[(keys[i],keys[j])].append(half_life(residual+100))\n",
    "            except Exception, e: \n",
    "                print \"出错：%s\"%str(e)\n",
    "                continue\n",
    "    return ret\n",
    "\n",
    "# 函数名：Cadf_test\n",
    "# 输入参数：\n",
    "# 1、sec1：比对的第一支股票\n",
    "# 2、sec2：比对的第二只股票\n",
    "# 3、ncount：样本数\n",
    "# 4、end_date：终止时间\n",
    "# 输出参数：\n",
    "# 序列：\n",
    "# Adf_factor,beta,alpha：分别表示Adf验证是否通过，kalman方程中的beta，kalman方程中的alpha\n",
    "# 功能：\n",
    "# 从给出的两个股票中，计算adf_factor、基于kalman方程的beta、基于的kalman方程的alpha\n",
    "def Cadf_test(sec1,sec2,ncount,end_date):\n",
    "    # 将股票改造成数组，并对参数赋初值\n",
    "    secs = [sec1, sec2]\n",
    "    ncount = ncount\n",
    "    end_date = end_date\n",
    "    \n",
    "    # 获得价格数据\n",
    "    p_data = get_price(secs, count =  ncount, end_date= end_date, frequency='1d', fields='close',fq = \"pre\")['close']\n",
    "\n",
    "    # 基于kalman方程获得alpha、beta\n",
    "    beta_kf = kalman_beta(sec1 = sec1 ,sec2 = sec2,count = ncount, end_date = end_date)\n",
    "    beta = beta_kf[0]\n",
    "    alpha = beta_kf[1]\n",
    "\n",
    "    # 利用alpha、beta计算两个股票的残差\n",
    "    # 注意：\n",
    "    # 1、股票1与股票2的顺序，sec2 = sec1 * beta + alpha\n",
    "    # 2、beta、alpha均包含在beta_kf中\n",
    "    price_pd = pd.DataFrame(p_data[secs[1]]- np.dot(sm.add_constant(p_data[secs[0]], prepend=False), beta_kf))\n",
    "    price_pd.columns = ['res']\n",
    "    \n",
    "    # 使用adf计算adf的值\n",
    "    cadf = ts.adfuller(price_pd[\"res\"])\n",
    "    \n",
    "    # 如果小于阈值，则可以以5%的置信度可以推翻Null hypothesis\n",
    "    # null hypothesis:  there isn't a cointegrating relationship at the 5% level.\n",
    "    if cadf[1] < 0.01:\n",
    "        return True,beta,alpha\n",
    "    else:\n",
    "        return False,beta,alpha\n",
    "\n",
    "    \n",
    "# 函数名：hurst\n",
    "# 输入参数：\n",
    "# 1、ts：残差序列\n",
    "# 输出参数：\n",
    "# 大于0.5则说明是趋势，小于0.5均值回复\n",
    "def hurst(ts):\n",
    "    \"\"\"Returns the Hurst Exponent of the time series vector ts\"\"\"\n",
    "    # Create the range of lag values\n",
    "    lags = range(2, 100)\n",
    "\n",
    "    # Calculate the array of the variances of the lagged differences\n",
    "    tau = [sqrt(std(subtract(ts[lag:], ts[:-lag]))) for lag in lags]\n",
    "\n",
    "    # Use a linear fit to estimate the Hurst Exponent\n",
    "    poly = polyfit(log(lags), log(tau), 1)\n",
    "\n",
    "    # Return the Hurst exponent from the polyfit output\n",
    "    return poly[0]*2.0\n",
    "\n",
    "\n",
    "#计算Pearson系数\n",
    "def calcPearson(x,y):\n",
    "    #计算特征和类的平均值\n",
    "    def _calcMean(x,y):\n",
    "        sum_x = sum(x)\n",
    "        sum_y = sum(y)\n",
    "        \n",
    "        n = len(x)\n",
    "        if n != 0:\n",
    "            x_mean = float(sum_x+0.0)/n\n",
    "            y_mean = float(sum_y+0.0)/n\n",
    "            return x_mean,y_mean\n",
    "        else:\n",
    "            return 1,1\n",
    "    x_mean,y_mean = _calcMean(x,y)\t#计算x,y向量平均值\n",
    "    n = len(x)\n",
    "    sumTop = 0.0\n",
    "    sumBottom = 0.0\n",
    "    x_pow = 0.0\n",
    "    y_pow = 0.0\n",
    "    for i in range(n):\n",
    "        sumTop += (x[i]-x_mean)*(y[i]-y_mean)\n",
    "    for i in range(n):\n",
    "        x_pow += math.pow(x[i]-x_mean,2)\n",
    "    for i in range(n):\n",
    "        y_pow += math.pow(y[i]-y_mean,2)\n",
    "    sumBottom = math.sqrt(x_pow*y_pow)\n",
    "    if sumBottom != 0:\n",
    "        p = sumTop/sumBottom\n",
    "        return p\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# 计算P半衰期\n",
    "# 看是否能在半衰期内均值回复\n",
    "def half_life(time_series):\n",
    "    \n",
    "    # np.roll的功能如下：\n",
    "    # >>> x = np.arange(10)\n",
    "    # >>> np.roll(x, 2)\n",
    "    # array([8, 9, 0, 1, 2, 3, 4, 5, 6, 7])\n",
    "    lag = np.roll(time_series, 1)\n",
    "    \n",
    "    # 第一个置为0 \n",
    "    lag[0] = 0\n",
    "    \n",
    "    # 去中间的差，并且第一个设置为0\n",
    "    ret = time_series - lag\n",
    "    ret[0] = 0\n",
    "\n",
    "    # lag 作为自变量\n",
    "    # adds intercept terms to X variable for regression\n",
    "    lag2 = sm.add_constant(lag)\n",
    "\n",
    "    # 线性拟合，确定beta\n",
    "    model = sm.OLS(ret, lag2)\n",
    "    res = model.fit()\n",
    "\n",
    "    half_life = -np.log(2) / res.params[1]\n",
    "    \n",
    "    return half_life\n",
    "\n",
    "\n",
    "# 函数名：kalman_beta\n",
    "# 输入参数：\n",
    "# 1、sec1：比对的第一支股票\n",
    "# 2、sec2：比对的第二只股票\n",
    "# 3、ncount：样本数\n",
    "# 4、end_date：终止时间\n",
    "# 输出参数：\n",
    "# state_means，同时包含了beta、alpha\n",
    "# 第1个参数为beta\n",
    "# 第2个参数为alpha\n",
    "def kalman_beta(sec1 = '000858.XSHE' ,sec2 = '000300.XSHG',count = 400, end_date = '2015-3-1'):\n",
    "    # 赋初值\n",
    "    secs = [sec1, sec2]\n",
    "    ncount = count\n",
    "    end_date = end_date\n",
    "    \n",
    "    # 获取价格数据\n",
    "    data = get_price(secs, count =  ncount, end_date= end_date, frequency='1d', fields='close',fq = \"pre\")['close']\n",
    "    data.index.name = 'Date'\n",
    "    \n",
    "    # 观察矩阵\n",
    "    # 注意：\n",
    "    # 1、观察到的是sec1数据，sec1是自变量x，sec2是因变量y\n",
    "    # 2、需要使用add_constant来模拟alpha\n",
    "    # 3、需要使用np.newaxis来增加维度\n",
    "    obs_mat = sm.add_constant(data[secs[0]].values, prepend=False)[:, np.newaxis]\n",
    "\n",
    "    kf = KalmanFilter(n_dim_obs=1, n_dim_state=2, # y is 1-dimensional, (alpha, beta) is 2-dimensional\n",
    "                  initial_state_mean=np.ones(2),\n",
    "                  initial_state_covariance=np.ones((2, 2)),\n",
    "                  transition_matrices=np.eye(2),  # 不发生变化，都是单位矩阵\n",
    "                  observation_matrices=obs_mat,   # 观察矩阵\n",
    "                  observation_covariance=10**2,\n",
    "                  transition_covariance=0.01**2 * np.eye(2))\n",
    "    \n",
    "    # 相当于使用sec2来进行训练，模拟出beta、alpha\n",
    "    state_means, state_covs = kf.filter(data[secs[1]][:, np.newaxis])\n",
    "    return state_means[-1]\n",
    "\n",
    "#6 R/S算法计算Hurst\n",
    "#变量：x-日收益率-list(之后使用np.array变换成数组) \n",
    "#输出：计算得到的Hurst值\n",
    "def hurst_joinquant(X):\n",
    "    \n",
    "    #输入日回报率\n",
    "    X = np.array(X)\n",
    "    \n",
    "    #N代表最大的片段值（即不对X分割时）\n",
    "    N = X.size\n",
    "    \n",
    "    T = np.arange(1, N + 1)\n",
    "    Y = np.cumsum(X)\n",
    "    \n",
    "    #分别计算不同长度的片段的均值\n",
    "    Ave_T = Y / T\n",
    "\n",
    "    #每个片段的最大差距R_T\n",
    "    R_T = np.zeros(N)\n",
    "    #对应的每段的标准差S_T\n",
    "    S_T = np.zeros(N)\n",
    "    \n",
    "    #分别对不同的大小的切片计算R_T和S_T\n",
    "    for i in range(N):\n",
    "        S_T[i] = np.std(X[:i + 1])\n",
    "        Z_T = Y - T * Ave_T[i]\n",
    "        R_T[i] = np.ptp(Z_T[:i + 1])\n",
    "        \n",
    "    #计算R/S\n",
    "    R_S = R_T / S_T\n",
    "    \n",
    "    #将lg(R/S)作为被解释变量Y\n",
    "    R_S = np.log(R_S)[1:]\n",
    "    \n",
    "    #将lgt作为解释变量X\n",
    "    n = np.log(T)[1:]\n",
    "    A = np.column_stack((n, np.ones(n.size)))\n",
    "    \n",
    "    #回归得到的斜率即为hurst指数\n",
    "    [m, c] = np.linalg.lstsq(A, R_S)[0]\n",
    "    H = m\n",
    "    return H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3、使用上面定义的函数进行配对数据提取\n",
    "\n",
    "并存入文件中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_pd = get_pairs(\"2018-6-10\",200)\n",
    "\n",
    "# 确定文件名\n",
    "file_name = \"kalman_pairs.csv\"\n",
    "\n",
    "# 写入文件\n",
    "write_file(file_name, pairs_pd.to_csv(), append=False) #写到文件中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>pearson</th>\n",
       "      <th>adf</th>\n",
       "      <th>beta</th>\n",
       "      <th>alpha</th>\n",
       "      <th>hurst</th>\n",
       "      <th>half-life</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600096.XSHG</td>\n",
       "      <td>603585.XSHG</td>\n",
       "      <td>0.868464</td>\n",
       "      <td>True</td>\n",
       "      <td>3.101326</td>\n",
       "      <td>3.08546</td>\n",
       "      <td>0.227525</td>\n",
       "      <td>31.704278</td>\n",
       "      <td>C13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600096.XSHG</td>\n",
       "      <td>603585.XSHG</td>\n",
       "      <td>0.868464</td>\n",
       "      <td>True</td>\n",
       "      <td>3.101326</td>\n",
       "      <td>3.08546</td>\n",
       "      <td>0.227525</td>\n",
       "      <td>31.704278</td>\n",
       "      <td>C14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            p1           p2   pearson   adf      beta    alpha     hurst  \\\n",
       "0  600096.XSHG  603585.XSHG  0.868464  True  3.101326  3.08546  0.227525   \n",
       "0  600096.XSHG  603585.XSHG  0.868464  True  3.101326  3.08546  0.227525   \n",
       "\n",
       "   half-life category  \n",
       "0  31.704278      C13  \n",
       "0  31.704278      C14  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs_pd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
